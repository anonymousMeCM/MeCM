from MeCM import MeCM

import random
import numpy as np
import os
from tqdm import tqdm
import torch
import time
from DataLoader import DataLoader
# np.random.seed(2021)
# torch.manual_seed(2021)

def training(model, config, model_save=False, saved_filename=None, device=torch.device('cpu')):
    print('training model...')
    if config['use_cuda']:
        model.cuda()
    model.train()

    print('loading train data...')
    dataset = config["dataset"]
    train_data,num_train_tasks = data_loader.load_data(dataset=dataset, state='train')
    test_data,num_test_tasks= data_loader.load_data(dataset=dataset, state='test')

    # print("Training tasks: {}".format(num_train_tasks))
    # print("Test tasks: {}".format(num_test_tasks))
    # split_test_data = data_loader.split_test_data(dataset=dataset)

    batch_size = config['batch_size']
    num_epoch = config['num_epoch']
    num_batch = int(num_train_tasks / batch_size)
    for epoch_i in range(num_epoch):
        loss, mae, rmse = [], [], []
        ndcg_at_1, ndcg_at_3, ndcg_at_5 = [],[],[]
        start = time.time()

        random.shuffle(train_data)
        train_task_id_all, support_x_u_all, support_x_v_all, support_y_all, query_x_u_all, query_x_v_all, query_y_all = zip(*train_data)
        for batch_i in tqdm(range(num_batch)):
        # for batch_i in range(3):
            task_ids = list(train_task_id_all[batch_size * batch_i:batch_size * (batch_i + 1)])
            support_xs_u = list(support_x_u_all[batch_size * batch_i:batch_size * (batch_i + 1)])
            support_xs_v = list(support_x_v_all[batch_size * batch_i:batch_size * (batch_i + 1)])
            support_ys = list(support_y_all[batch_size * batch_i:batch_size * (batch_i + 1)])

            query_xs_u = list(query_x_u_all[batch_size * batch_i:batch_size * (batch_i + 1)])
            query_xs_v = list(query_x_v_all[batch_size * batch_i:batch_size * (batch_i + 1)])
            query_ys = list(query_y_all[batch_size * batch_i:batch_size * (batch_i + 1)])

            _loss, _mae, _rmse, _ndcg_1,_ndcg_3, _ndcg_5 = model.global_update(task_ids,support_xs_u, support_xs_v,support_ys,query_xs_u ,query_xs_v, query_ys, device)
            loss.append(_loss)
            mae.append(_mae)
            rmse.append(_rmse)
            ndcg_at_1.append(_ndcg_1)
            ndcg_at_3.append(_ndcg_3)
            ndcg_at_5.append(_ndcg_5)

        print('epoch: {}, loss: {:.6f}, cost time: {:.1f}s, mae: {:.5f}, rmse: {:.5f},  ndcg@1: {:.5f}, ndcg@3: {:.5f}, ndcg@5: {:.5f}'.
              format(epoch_i, np.mean(loss), time.time() - start, np.mean(mae), np.mean(rmse),np.mean(ndcg_at_1),np.mean(ndcg_at_3),np.mean(ndcg_at_5)))
        if epoch_i % 1 == 0:
            testing(model,test_data, device)
            # split_testing(model,split_test_data,device)
            model.train()

    if model_save:
        print("*******************start saving model!************************")
        torch.save(model.state_dict(), saved_filename[0])
        print("*******************saved in {}!************************".format(saved_filename[0]))
        model.taskmemory.save_weights(saved_filename[1])
        print("*******************saved in {}!************************".format(saved_filename[1]))

def split_testing(model,split_test_data,device='cpu'):
    print('evaluating model...')
    if config['use_cuda']:
        model.cuda()
    model.eval()

    for size_i,data_i in split_test_data.items():
        test_task_id_all, support_x_u_all, support_x_v_all, support_y_all, query_x_u_all, query_x_v_all, query_y_all = zip(*data_i)

        loss, mae, rmse = [], [], []
        ndcg_at_1, ndcg_at_3, ndcg_at_5 = [], [], []
        for i in range(len(support_x_u_all)):  # each task
            _mae, _rmse, _ndcg_1, _ndcg_3, _ndcg_5 = model.evaluation(test_task_id_all[i], support_x_u_all[i],
                                                                      support_x_v_all[i], support_y_all[i],
                                                                      query_x_u_all[i], query_x_v_all[i], query_y_all[i],
                                                                      device)
            mae.append(_mae)
            rmse.append(_rmse)
            ndcg_at_1.append(_ndcg_1)
            ndcg_at_3.append(_ndcg_3)
            ndcg_at_5.append(_ndcg_5)

        print('support_size: less {}, mae: {:.5f}, rmse: {:.5f}, ndcg@1: {:.5f}, ndcg@3: {:.5f}, ndcg@5: {:.5f}'.
              format(size_i, np.mean(mae), np.mean(rmse), np.mean(ndcg_at_1), np.mean(ndcg_at_3), np.mean(ndcg_at_5)))


def testing(model, test_data, device='cpu'):
    print('evaluating model...')
    if config['use_cuda']:
        model.cuda()
    model.eval()

    test_task_id_all, support_x_u_all, support_x_v_all, support_y_all, query_x_u_all, query_x_v_all, query_y_all = zip(*test_data)

    loss, mae, rmse = [], [], []
    ndcg_at_1,ndcg_at_3,ndcg_at_5 = [],[],[]

    for i in range(len(support_x_u_all)):  # each task
        _mae, _rmse, _ndcg_1,_ndcg_3,_ndcg_5 = model.evaluation(test_task_id_all[i],support_x_u_all[i], support_x_v_all[i], support_y_all[i], query_x_u_all[i], query_x_v_all[i], query_y_all[i], device)
        mae.append(_mae)
        rmse.append(_rmse)
        ndcg_at_1.append(_ndcg_1)
        ndcg_at_3.append(_ndcg_3)
        ndcg_at_5.append(_ndcg_5)

    print('mae: {:.5f}, rmse: {:.5f}, ndcg@1: {:.5f}, ndcg@3: {:.5f}, ndcg@5: {:.5f}'.
          format(np.mean(mae), np.mean(rmse), np.mean(ndcg_at_1),np.mean(ndcg_at_3),np.mean(ndcg_at_5)))

if __name__ == "__main__":
    os.environ["CUDA_VISIBLE_DEVICES"] = "0"
    dataset = "yelp"
    model_name = "MeCM"

    if dataset == "yelp":
        from Configurations_Yelp import Yelp_config as config

    print("Start time:{}".format(time.strftime("%Y-%m-%d %H:%M:%S", time.localtime())))
    print("Configurationsï¼š")
    print(config)

    Input_dir = "dataset/{}/Final_10".format(dataset)
    data_loader = DataLoader(Input_dir,config)


    model_name = "MeCM"
    model = MeCM(config, model_name)
    print('--------------- {} ---------------'.format(model_name))

    cuda_or_cpu = torch.device("cuda" if config['use_cuda'] else "cpu")


    # training(model, config, model_save = config['model_save'], saved_filename=saved_filename, device=cuda_or_cpu)
    training(model, config, model_save = config['model_save'], device=cuda_or_cpu)
